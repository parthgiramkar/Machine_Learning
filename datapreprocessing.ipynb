{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing the library"
      ],
      "metadata": {
        "id": "7TKB7UMKtV3m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYOJ6Urvpu0F"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as py     #.pyplot to access the pyplot module from matplotlib\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "H1rWYOBjs-jN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the dataset"
      ],
      "metadata": {
        "id": "VN6772kVti3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pandas lib function is used\n",
        "dataset = pd.read_csv('Data.csv')\n",
        "\n",
        "#for independent variable i.e input\n",
        "x = dataset.iloc[ : , : -1].values                           #iloc function of pandas lib(locate index) lbound:upperb -the range of row and cols respectively the ub gets excluded\n",
        "                                                            #.values this converts the DataFrame into a NumPy array\n",
        "#for dependent variable i.e output\n",
        "y = dataset.iloc[ : , -1].values"
      ],
      "metadata": {
        "id": "iZ9G3xRosjyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-RjTIbu5ScM",
        "outputId": "fb35916b-9dd8-48f5-c56d-4743fd808ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PY-NmPE5UNO",
        "outputId": "92924c0a-b873-4c35-fc24-3a860c2b19c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replacing the Missing Data\n"
      ],
      "metadata": {
        "id": "n5aK0lg-5dTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#By taking the average of that column\n",
        "from sklearn.impute import SimpleImputer           #SimpleImputer class from sklearn.impute is a part of the scikit-learn library used to handle missing data in datasets\n",
        "imputer = SimpleImputer( missing_values=np.nan , strategy='mean' )         #creating object of that class , means to find the nan value of that col\n",
        "imputer.fit(x[ : , 1:3])                             #Fit It only computes the required statistics no changes are made to the dataset..\n",
        "x[ : , 1:3] = imputer.transform(x[ : , 1:3])             #transform method is used to replace the missing values and reassinged to x[ : , 1:3] impute means missing data\n"
      ],
      "metadata": {
        "id": "FLNZAwhr7lpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmrIu0ujKw5f",
        "outputId": "2d1c3031-ff81-4337-e3d0-791687be28f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding Categorical Data i.e country col(ind)"
      ],
      "metadata": {
        "id": "4YWd0OIwL98t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use One-Hot Encoding when the categorical feature has no natural ordering features like \"Color\" (Red, Blue, Green) or \"Animal\" (Dog, Cat, Bird) are nominal\n",
        "# Not Too Many Unique Categories\n",
        "from sklearn.compose import ColumnTransformer         #ColumnTransformer in scikit-learn is used to apply transformations to specific columns of your dataset ,while allowing other cols to remain unchanged\n",
        "from sklearn.preprocessing import OneHotEncoder       #combined with OneHotEncoder, it can efficiently handle categorical data by encoding categorical cols into binary vectors\n",
        "\n",
        "ct =  ColumnTransformer( transformers =[ ( 'encoder' , OneHotEncoder() , [0 ]) ] , remainder='passthrough' )  #as onehtenc is class i.e which method to apply remainder='passthrough' i.e salary&age where onehtenc will not be applied                                             #creating obj of class three arg - 1.    2.type of encoding 3.on index we want to apply onehtenc\n",
        "x = np.array(ct.fit_transform(x))         #as used above but now in combine form\n",
        "# particularly useful when your dataset has both categorical and numerical features the lib\n",
        "#  synatx : - ColumnTransformer(transformers=[(name, transformer, columns)], remainder='passthrough')  the transfomers is a tuple\n"
      ],
      "metadata": {
        "id": "m2rhp2DaLatr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKOxOb8h9k69",
        "outputId": "82df18fc-67d8-4c94-ea4f-25291f042554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  Encoding the Dependent variables(purchased col)"
      ],
      "metadata": {
        "id": "LC8bdmStCZGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder                    #LabelEncoder A class used to convert categorical labels into numerical labels.\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)                              #OneHotEncoder: The class that defines how to convert categorical data into binary vectors.fit_transform: The method that applies the encoding process by:\n",
        "                                              #Learning the unique categories (fit) Transforming the data into one-hot-encoded vectors (transform).\n",
        "\n"
      ],
      "metadata": {
        "id": "UJwto3aLEmFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6i1U_7RFouj",
        "outputId": "836f2c18-3eac-4022-c56c-78126bb789ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the dataset into training set and testing set"
      ],
      "metadata": {
        "id": "9FkWOdkhFsbC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train , x_test , y_train , y_test = train_test_split( x ,y , test_size=0.2 , random_state=1)  #test_size=0.2 means it will predict 2 cases 8 will be for training\n",
        "#with random_state=1, the output will be the same every time, giving you the same training and testing data.\n",
        "#If you do not set random_state (i.e., leave it as the default, which is None), the random shuffling will be different every time the code is executed.\n",
        "#train_test_split function returns two pairs of arrays: one for x and for y dataset change in order then mismatch"
      ],
      "metadata": {
        "id": "XkNBrJ5gINmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FRi2q6MLUTH",
        "outputId": "9b7d7264-28d0-4821-e844-ea3f8077c3d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( x_test )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPxItVdWLbRO",
        "outputId": "82a16fb0-5eae-4e66-a136-b824944d2f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( y_train )                                #these 8 y_train coressponds to the 8 same x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzvd9__hLgtg",
        "outputId": "c3eee049-2cbb-45de-8779-9b0efba7e935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laQiCHPJL2JS",
        "outputId": "c180ae1f-b6db-43a1-c455-fef63c40e164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Scaling After Train-Test Split Prevents Data Leakage Ensures Unbiased Testing:"
      ],
      "metadata": {
        "id": "bu4QVx99Qs7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Scaling ----  . It involves transforming the features (input variables) in a dataset so that they are on the same scale, making the model training more efficient and stable. common method - Standardization (also known as Z-score normalization) is widely used in many ml algorithms  especially when features have different scales or units."
      ],
      "metadata": {
        "id": "yPNcSZX8Qzj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler     #StandardScaler is used for feature scaling i.e standardization, which transforms the data to\n",
        "sc = StandardScaler()                                                    #have a mean of 0 and a standard deviation of 1.sc = StandardScaler()\n",
        "\n",
        "x_train[:, :3] = sc.fit_transform(x_train[:, :3])\n",
        "x_test[:, 3:] = sc.transform(x_test[:, 3:])     #fit_transformto intger variable only not the dummy var\n",
        " #transform() method applies the scaling learned from x_train to x_test\n"
      ],
      "metadata": {
        "id": "eOfgJdjdQ1e_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nw9HHc5xXioL",
        "outputId": "9cba6374-3992-4129-c5a7-9811201c7350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 -0.5773502691896258 1.2909944487358056 38.77777777777778 52000.0]\n",
            " [0.0 1.7320508075688774 -0.7745966692414834 40.0 63777.77777777778]\n",
            " [1.0 -0.5773502691896258 -0.7745966692414834 44.0 72000.0]\n",
            " [0.0 -0.5773502691896258 1.2909944487358056 38.0 61000.0]\n",
            " [0.0 -0.5773502691896258 1.2909944487358056 27.0 48000.0]\n",
            " [1.0 -0.5773502691896258 -0.7745966692414834 48.0 79000.0]\n",
            " [0.0 1.7320508075688774 -0.7745966692414834 50.0 83000.0]\n",
            " [1.0 -0.5773502691896258 -0.7745966692414834 35.0 58000.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Acm2kFpqXnOO",
        "outputId": "e3cf8857-7f1a-4a01-87ad-8b47a7f0329b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.0 1.0 0.0 68.70468203356548 111541.14577410436]\n",
            " [1.0 0.0 0.0 84.870489570875 138393.8303078091]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" 1 ] pandas : -\n",
        "Role: Handling and analyzing data.\n",
        "Key Points:\n",
        "Works with tabular data (like Excel sheets) using DataFrames.\n",
        "Helps in reading data from files (CSV, Excel), cleaning, and manipulating it.\n",
        "Example: pd.read_csv('data.csv') reads data from a CSV file.        \"\"\""
      ],
      "metadata": {
        "id": "vSoyfBoqb_Cw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"2 ] matplotlib.pyplot (as plt):\n",
        "Role: Creating visualizations.\n",
        "Key Points:\n",
        "Used to make graphs like line plots, bar charts, histograms, etc.\n",
        "Helps in visualizing data trends and patterns.\n",
        "Example: plt.plot(x, y) creates a line plot. \"\"\""
      ],
      "metadata": {
        "id": "Zhk078Xkb_Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"3] numpy (as np):\n",
        "Role: Working with numerical data.\n",
        "Key Points:\n",
        "Handles arrays (like lists but faster and more powerful).\n",
        "Supports mathematical operations (like addition, multiplication) on large datasets.\n",
        "Example: np.array([1, 2, 3]) creates a NumPy array.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ytUFsPOrcMea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"4 ]  seaborn as sns\n",
        "Yes, both Matplotlib and Seaborn are used for data visualization, but Seaborn provides a\n",
        "higher-level interface for statistical graphics, making it easier to create complex plots with better styling by default.\"\"\""
      ],
      "metadata": {
        "id": "xig22QMxcRyr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}